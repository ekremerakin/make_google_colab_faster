{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekremerakin/make_google_colab_faster/blob/master/Make_Google_Colab_25x_Faster.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to Google Drive."
      ],
      "metadata": {
        "id": "pmA4y6DDcCeD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wzOBmd53QcM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copying the zipped dataset into the local directory of Google Colab. Change the `fill_the_file_name` with your own file path."
      ],
      "metadata": {
        "id": "w-8kT7LXcF0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8523P0kO3axE"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/fill_the_file_name.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/dataset\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxr3iBe94EOh"
      },
      "source": [
        "# Training performance check"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used a dataset called LFW to test the performance difference. LFW is a face recognition dataset and includes over 5k individuals. You can download the dataset and try out your own. Also, you can try out with your own dataset here but you might need to do some adjustments.\n",
        "\n",
        "Change the `fill_the_dataset_dir` or other file directories depending on your needs."
      ],
      "metadata": {
        "id": "rn3KujZDbpA0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI4RwB2b4KHO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "# Reading from Google Colab\n",
        "input_path = \"/content/dataset/\"\n",
        "\n",
        "# Reading from Google Drive\n",
        "# input_path = '/content/drive/MyDrive/fill_the_dataset_dir'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUB4OoWr7BgM"
      },
      "outputs": [],
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "}\n",
        "\n",
        "image_datasets = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(input_path, data_transforms['train'])\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    'train':\n",
        "    torch.utils.data.DataLoader(image_datasets['train'],\n",
        "                                batch_size=32,\n",
        "                                shuffle=True,\n",
        "                                num_workers=0)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_oeOeVD7RbF"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgzVqv9A7SX4"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(pretrained=True).to(device)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(512, 5749)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters())\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(model, (3, 112, 112))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpsNjIjc4Ue3"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=3):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(image_datasets[phase])\n",
        "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
        "\n",
        "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
        "                                                        epoch_loss,\n",
        "                                                        epoch_acc))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyEqs0iH5ZHj"
      },
      "outputs": [],
      "source": [
        "import time as t\n",
        "\n",
        "start_time = t.time()\n",
        "model_trained = train_model(model, criterion, optimizer, num_epochs=1)\n",
        "end_time = t.time()\n",
        "\n",
        "print(end_time-start_time)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNHfkKjNB1TNeb+RMS7hPbZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}